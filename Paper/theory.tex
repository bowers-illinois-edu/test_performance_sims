\documentclass[11pt]{article}
\usepackage{amssymb,amsmath,lscape,amsthm}
\usepackage[ruled]{algorithm2e}
\usepackage[T1]{fontenc}
\usepackage{libertine}
\usepackage[scaled=0.83]{FiraSans}
\usepackage[scaled=0.83]{FiraMono}
\usepackage{upquote}
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
\usepackage{parskip}
\usepackage{fancyvrb}
\usepackage{hyperref}
\hypersetup{pdfborder={0 0 0},
            breaklinks=true}

\usepackage[margin=1.5in]{geometry}
\usepackage{graphicx,grffile}
\usepackage{float} % for the H option
\usepackage{lscape}
\usepackage{pdflscape}

\setlength{\emergencystretch}{3em}  % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\setcounter{secnumdepth}{4}

% set default figure placement to htbp
% \makeatletter
% \def\fps@figure{htbp}
% \makeatother

%\usepackage[apaciteclassic]{apacite}
%\bibliographystyle{apacite}
\usepackage[style=authoryear, backend=biber]{biblatex}
%\usepackage{biblatex}
%\addbibresource{tmp.bib}
%\addbibresource{/Users/jwbowers/repos/Research-Group-Bibliography/big.bib}
\addbibresource{../BIB/references.bib}

\title{Why does the top-down tree-shaped hypothesis testing procedure control family wise error rates?}
\providecommand{\subtitle}[1]{}
\subtitle{Draft. Do not circulate or cite without permission. Comments welcome.}
\author{Jake Bowers and David Kim}
\date{\today}

% For tables
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[table]{xcolor}
\usepackage{array}
\newcolumntype{G}{@{}>{\centering\arraybackslash}p{6ex}@{}}

\newcommand{\gta}{$>\!\alpha$}
\newcommand{\gga}{$\gg\!\alpha$}
\newcommand{\ggga}{$\ggg\!\alpha$}
\newcommand{\lea}{$\le\!\alpha$}
\newcommand{\leab}{\cellcolor{lightgray}\lea}

\usepackage{tikz}
%\usepackage{pgfplots}
\usepackage{mathtools}
\usepackage{tikz-cd}
\usetikzlibrary{arrows,automata,positioning,trees,fit,graphs,ext.nodes,ext.node-families}
\usepackage{forest}

% for the sparklines maybe skip this

\usepackage{sparklines}
% The height of the sparklines in ex units
\renewcommand\sparklineheight{1.75}
% The line width
\setlength\sparklinethickness{0.4pt}
% The color of the sparkline
\definecolor{sparklinecolor}{named}{blue}
% The color of the sparkine rectangle when present
\definecolor{sparkrectanglecolor}{gray}{0.8}
% The dot width
\setlength\sparkdotwidth{2pt}
% The color of the spikes
\definecolor{sparkspikecolor}{named}{red}
% The color of the bottom line when present
\definecolor{bottomlinecolor}{gray}{0.2}
% The thickness of the bottom line
\setlength\sparkbottomlinethickness{.2pt}
% The clipping separation (need sparklines v1.7 or later)
\setlength\sparklineclipsep{1pt}

\newcommand{\pfn}{\text{pfn}}
\newcommand{\bset}{\mathcal{B}}
\newcommand{\splitfn}{\text{splitfn}}
\newcommand{\bZ}{\bm{Z}}
\newcommand{\bS}{\bm{S}}
\newcommand{\bz}{\bm{z}}
\newcommand{\bOne}{\bm{1}}
\newcommand{\hyp}[1]{H_{\bset_{#1}}}
\newcommand{\p}[1]{p_{\bset_{#1}}}
%% Trying a way to include comments.
\usepackage[todonotes={textsize=footnotesize}]{changes}
%\usepackage{todonotes}
\definechangesauthor{JB}


\tikzcdset{arrow style=tikz, diagrams={>=stealth}}

\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}

\begin{document}
\maketitle

This section explains the theory behind the method.

\section{Recap of the method and notation}

Imagine that we have hypotheses ordered in an inverted tree-like structure as
shown in Figure~\ref{fig:simp_alg}.  We use this ordering to impose a
\textbf{stopping rule} and a \textbf{monotonicity rule}.\footnote{We combine
the \autocite{goeman2010sequential}, \autocite{goeman2012inheritance}, and
\autocite{rosenbaum2008a} ideas.} We show below that these rules allow weak
control of the family wise error rate (FWER) of testing the multiple hypotheses
represented in the tree --- control of the FWER when all of the hypotheses in
the tree are true. Then we show that these rules are not sufficient for strong
control of the FWER and add two rules which allow such control.



\begin{figure}[h]
\centering
\begin{tikzcd}[column sep=2em,
  row sep=small,
  every label/.append style={font=\footnotesize},
%  /tikz/execute at end picture={
%    \node (large) [rectangle, draw, fit=(H0)] {};
%}
  ]
	&& |[alias=H0]| {H_{\bset_{0}}} & {\text{Stop}} \\
	&& {\text{Split and Test}} \\
	{\text{Stop}} & {H_{\bset_{1}}} && {H_{\bset_{2}}} & {\text{Stop}} \\
	& {\text{Split and Test}} && {\text{Split and Test}} \\
	{H_{\bset_{3}}} & {H_{\bset_{4}}} && {H_{\bset_{5}}} & {H_{\bset_{6}}}
	\arrow[from=1-3, to=1-4, "{\text{if } p_{\bset_{0}} > \alpha}",]
	\arrow[from=1-3, to=2-3, "{\text{if } p_{\bset_{0}} \le \alpha}",]
	\arrow[from=2-3, to=3-2]
	\arrow[from=2-3, to=3-4]
	\arrow[from=3-2, to=3-1,"{p_{\bset_{1}} > \alpha}",above,sloped]
	\arrow[from=3-2, to=4-2,"{p_{\bset_{1}} \le \alpha}"]
	\arrow[from=3-4, to=3-5,"{p_{\bset_{2}} > \alpha}"]
	\arrow[from=3-4, to=4-4,"{p_{\bset_{2}} \le \alpha}"]
	\arrow[from=4-2, to=5-1]
	\arrow[from=4-2, to=5-2]
	\arrow[from=4-4, to=5-4]
	\arrow[from=4-4, to=5-5]
\end{tikzcd}

  \caption{The structured approach with fixed false positive rate $\alpha$. All
    blocks are in set $\bset_0$. All other hypotheses are subsets of those
    higher on the path and disjoint from others not on the same path. For
    example, $\bset_1 \subset \bset_0$ and $\bset_1 \cap \bset_2=\emptyset$.
    The $p$-value, $p_0$, is the result from a test of the hypothesis of no
    effects using all the blocks, $p_1$ is the $p$-value from a test using only
    the blocks in $\bset_1$. Testing stops when $p > \alpha$ or when the number
    of blocks in a given set of blocks $\bset$, $|\bset|$, is
  1.}\label{fig:simp_alg}

\end{figure}
%https://q.uiver.app/#q=WzAsMTMsWzIsMCwiSF97XFxic2V0X3swfX0iXSxbMSwyLCJIX3tCX3sxfX0iXSxbMywyLCJIX3tCX3syfX0iXSxbMCw0LCJIX3tCX3sxMX19Il0sWzEsNCwiSF97Ql97MTJ9fSJdLFszLDQsIkhfe0JfezIxfX0iXSxbNCw0LCJIX3tCX3syMn19Il0sWzIsMSwiXFx0ZXh0e1NwbGl0fSJdLFszLDAsIlxcdGV4dHtTdG9wfSJdLFswLDIsIlxcdGV4dHtTdG9wfSJdLFsxLDMsIlxcdGV4dHtTcGxpdH0iXSxbMywzLCJcXHRleHR7U3BsaXR9Il0sWzQsMiwiXFx0ZXh0e1N0b3B9Il0sWzAsNywiXFx0ZXh0e2lmIH0gcF97XFxic2V0X3swfX0gXFxsZSBcXGFscGhhIiwyXSxbNywxXSxbNywyXSxbMiwxMl0sWzIsMTFdLFsxLDldLFsxMCwzXSxbMTAsNF0sWzExLDVdLFsxMSw2XSxbMSwxMF0sWzAsOCwiXFx0ZXh0e2lmIH0gcF97XFxic2V0X3swfX0gPiBcXGFscGhhIl1d&macro_url=https%3A%2F%2Fgist.githubusercontent.com%2Fjwbowers%2Fc985bd71a3ec90b4e3d7e82595a8d6db%2Fraw%2F1ff36ee70583a2289e25eaa5d4bfe9fbdd51dcbd%2Fgistfile1.txt

We explain the rules here and then use them in propositions 1 and 2 and their
related proofs and simulation studies, below.

\paragraph*{Notation} We use $\bset$ to refer to the set of blocks relevant to
a given hypothesis. And write $\hyp{0}$ to refer to the hypothesis of no
effects focused on all blocks and units, $\hyp{1}$ to refer to the hypothesis
of no effects focused on the blocks and units in the subset $\bset_1$. Each
subset of blocks in the $k$-ary tree with $n$ nodes  $\bset_0, \ldots, \bset_{n}$ is (1) a subset of the whole, (2) a subset
of the other sets higher on the tree on the same path (for example $\bset_{2}
\subset \bset_{1} \subset \bset_0$), and (3) is disjoint from sets not on the
same path (for example $\bset_1 \cap \bset_2 = \emptyset$ and $\bset_{3} \cap
\bset_{4} = \emptyset$). Tests of hypotheses produce $p$-values, and those
$p$-values are labeled with the set to which they refer (so $\p{0}$ is the
$p$-value for the test of the hypothesis focused on $\bset_0$, and $\p{1}$ is
the $p$-value for the test focusing on those units and blocks in the set
$\bset_{1}$).


\subsection*{Rules of the method}

We list here all of the rules needed for both weak and strong control of the FWER.

\paragraph*{Rules required for weak control of the FWER} We will show below
that the following three rules suffice for weak control of the FWER.

\begin{description}

  \item[The \textbf{stopping rule}] instructs us to only
    test $\hyp{1}$ after rejecting $\hyp{0}$ and only test $\hyp{3}$ after
    rejecting $\hyp{1}$ (and thus after rejecting \emph{both} of the hypotheses
    that precede $\hyp{3}$ on that path of $\hyp{0} \rightarrow \hyp{1}
    \rightarrow \hyp{3}$). Any given hypothesis can only be tested
    if all its ancestor hypotheses on a path have been rejected. We stop
    testing once a hypothesis has not been rejected or once the path ends with
    a single block or node with no descendents (a ``leaf'' of the
    tree).

\item[The \textbf{monotonicity rule}] tells us that even if all ancestor
  hypotheses have been rejected, the critical value ($\alpha$) at which we
  reject a given hypothesis must be less than or equal to the critical value
  used in rejecting the ancestor hypotheses. In practice, with $\alpha$ fixed,
  following this rule amounts to a restriction that $p$-values never decrease
    along a path.(This is like the \textcite{goeman2010sequential}
  ``monotonicity'' assumption).


\item[The \textbf{false positive rate rule}]  In the case of fixed $\alpha$ we
  require that all tests, if executed on their own, have a false positive rate
  no more than $\alpha$. We can tend to justify this assumption because we
  could use direct permutations of randomized assignment to calculate these
  $p$-values, and this process plus our test statistic (which is effect
  increasing) should yield this kind of control \autocite[section
  TODO]{rosenbaum2002book}. (This is like the \textcite{goeman2010sequential}
  "single-step" assumption).

\end{description}

\paragraph*{Additional rules required for strong control of the FWER}
We then show that strong control of the FWER requires two more rules.

\begin{description}

  \item[The \textbf{sample splitting rule}] Although one could organize
    hypotheses in order where each hypothesis is tested on the same number of
    units (say the hypotheses are about different elements of an index) in this
    case, we require that the sample size at each node be strictly less than
    the sample size of its parent. This maps directly onto the application ---
    where we are trying to separate blocks or groups of blocks within which the
    treatment effect is detectable from those within which it is not
    detectable. In practice, the sample size goes down quickly. For example in
    a k-ary tree with $k=2$ nodes at each level below the root and $l=3$
    levels, and splitting the sample into equal numbers of blocks at each
    level, we have, say, $B$ total blocks used for $\hyp{0}$, $B/2$ blocks used
    for each of $\hyp{1}$ and $\hyp{2}$, and $(B/2)/2=B/4$ for each of
    $\hyp{3}, \ldots, \hyp{6}$ and $(B/4)/2=B/8$ for the nodes at the next
    level. This also implies limits on the sizes of the tree, with $B=100$, a
    tree with $k=2$ can have no more than $l=5$.\footnote{We know that the
    number of nodes in a complete $k$-ary tree is $(k^{l+1}-1)/(k-1)$ and the
    maximum number of levels in a tree with $k$ nodes at each level with $B$
    total nodes is $l = \left\lfloor \log_k \left( B (k - 1) + 1 \right)
    \right\rfloor - 1$.} This rule not necessary for control of the FWER in the
    weak sense --- it is not used in the proof below and we can show that
    simulation studies without sample splitting also control the FWER when all
    hypotheses are true.

  \item[The \textbf{local adjustment rule}] When some nodes have non-null
    effects (or are ancestors of leaves with non-null effects) then the gating
    imposed by the stopping rule is not enough to control the FWER given the
    multiple tests in parallel at a given level of the tree. That said, we do
    not need to adjust all of the $k^l$ tests at a given level given the other
    rules. Instead we can make an adjustment to the tests within each parent.
    So, in the above figure, we would make an adjustment for testing both
    $\hyp{1}$ and $\hyp{2}$, and then separately we would adjust  the
    $p$-values arising from the two tests of $\hyp{3}$ and $\hyp{4}$ separately
    from the two tests of $\hyp{5}$ and $\hyp{6}$. In our application we use
    the Hommel adjustment but one could also use a more conservative
    adjustment.\footnote{We think that this adjustment is conservative. We
    leave for another project the derivation of the optimal local adjustment.}

  \item[Optional rule: the \textbf{global adjustment rule}] It is possible that
    we can skip the local adjustment rule and just do a global adjustment after
    all of the nodes have been tested following the other rules. We may leave
    this rule for a different paper but we explored it in the simulations that
    we show below.

\end{description}

\section{Weak Control of the FWER using the rules}

We show here that the method described above controls the FWER when all of the
hypotheses are true. In fact, the proof that we show below does not require the
sample splitting step --- so that weak control can be shown to hold for
hypotheses organized into a tree-like structure even without the sample
reduction at each level of the tree, for example for covariates gathered into
indices, or other multi-item scores.


\begin{proposition}{The three rules suffice to control FWER all hypotheses are true}\label{prop:weakctrl}

  A family of hypotheses with individually controlled false positive rates, such
  as permutation tests from a randomized experiment, organized on a $k$-ary
  tree and tested following the stopping rule with a fixed $\alpha$ and
  monotonicity rules will produce no more than $\alpha$ false positive errors
  across the whole tree. That is, a family of hypotheses tested in this way
  will weakly control the FWER.

\end{proposition}


\begin{proof}{Proof of Proposition~\ref{prop:weakctrl}}\label{proof:prop_weakctrl}

  \paragraph*{Step 1. Control at the Root}

  Let $p_0$ be the p-value at the root (level 0). Because the test is valid by
  the \textbf{false positive rate rule}, we have $\Pr(p_0 \le \alpha) \le
  \alpha$.

  If $p_0 > \alpha$, the procedure stops immediately and no further tests occur
  because of the \textbf{stopping rule}. Therefore, any false rejection in the
  tree can occur only if $p_0 \le \alpha$.

  \paragraph*{Step 2. Consequence of the stopping rule.}

  Because of the stopping rule, a hypothesis node at any level is tested only
  if all its ancestor hypotheses had $p$-values $\le \alpha$. This means that,
  the event that any node in the tree is tested is a subset of the event of a
  false rejection at the root node, $\{p_0 \le \alpha\}$. Write the event
  of at least one false rejection on the tree as as $E$. The stopping rule
  makes this event a subset of the event of a false rejection at the
  root so $E \subseteq \{p_0 \le \alpha\}$.

  \paragraph*{Step 3. The law of total probability}

  Now, let’s use the law of total probability. We partition the sample space into
  two disjoint events: $A = \{p_0 \le \alpha\}$ (the root test is significant,
  so testing continues), $B = \{p_0 > \alpha\}$ (the root test is not
  significant, so no further tests occur).

  By the law of total probability, we have $\Pr(E) = \Pr(E \mid A)\Pr(A) + \Pr(E \mid B)\Pr(B)$.


  Notice that if $p_0 > \alpha$ (i.e. event $B$ occurs), then no tests beyond the
  root are performed and hence no false rejection can occur. Thus, $\Pr(E \mid
  B) = 0$.

  This simplifies our equation to $\Pr(E) = \Pr(E \mid A)\Pr(A)$.

  Since probabilities are bounded by 1, we have $\Pr(E \mid A) \le 1$ and because
  the test at the root is valid, we know $\Pr(A) = \Pr(p_0 \le \alpha) \le
  \alpha$.

  Combining these facts we obtain $\Pr(E) \le 1 \cdot \Pr(A) \le \alpha$.

  Thus, regardless of how many nodes or branches are tested later on, if $p_0 >
  \alpha$ then no tests beyond the root occur, and no false rejections are
  possible. At this point, we have only used the stopping rule and the false
  positive rule.

  \paragraph*{Step 3. Analysis Along a Branch}

  This result might seem strange. After all, we could have many tests at any
  level below the root (in fact $k^l$ at any given level). So, here we connect
  the results from the strictly nested testing approaches of
  \autocite{rosenbaum2008a} and \autocite{marcus1976closed} to the above.

  Suppose the root is rejected (i.e. $p_0 \le \alpha$); then the $k$ children
  at level $l=1$ are tested. Consider one branch from the root down through any
  number of nodes to a leaf. At the first level, for a given child, $\hyp{1}$,
  with parent’s p-value $p_0$, its conditional probability of being falsely
  rejected is $\Pr(p_{1} \le \alpha \mid p_0) = \frac{\alpha-p_0}{1-p_0} \le
  \alpha$.  We can write this probability as that fraction, because $p_0 \le
  \alpha$ and because the \textbf{false positive rule} implies that all of the
  p-values in this tree of true null hypotheses are draws from a uniform
  distribution between the parent p-values (by the \textbf{monotonicity rule})
  and 1.

  Similarly, for a node at level 2 along that branch, its test is only
  performed if the level 1 node was rejected. By the same logic, for example,
  with $\hyp{3}$ and it's parent $\hyp{1}$, $\Pr(p_{3} \le \alpha \mid
  p_1 \le \alpha) \le \alpha$, and so on.

  Thus, for any given branch, the probability that all tests along that branch
  yield rejections is at most the product of probabilities at each level and
  since the probabilities are all less than $\alpha$, the product is less than
  $\alpha$.

\paragraph*{An alternative approach:}

Consider a tree with two levels and $k$ nodes per level. In this case we have
$p_0$ (at the root or first level) and then $p_1, \ldots, p_k$ at the second
level. What is the probability of making at least one false positive error
among these tests?

We might write this as $\Pr(\min(p_0,p_1,\ldots,p_k) \le \alpha)$. By the
\textbf{false positive rule} we know that $\Pr(p_0 \le \alpha) \le \alpha$. By
the \textbf{monotonicity rule} and \textbf{stopping rule} we know that
$\min(p_0,p_1,\ldots,p_k) = p_0$. So, $\Pr(\min(p_0,p_1,\ldots,p_k) \le
\alpha)=\Pr(p_0 \le alpha) \le \alpha$.


  \paragraph*{Conclusion}

  This reasoning shows that even though there may be $k$ children at level 1,
  $k^2$ at level 2, and so on, the overall probability that any false rejection
  occurs in the tree is bounded by the probability that the root is falsely
  rejected by the \textbf{stopping rule} and \textbf{monotonicity rule} and
  \textbf{false positive rule}. Since the root is tested only once and its
  rejection probability is at most $\alpha$, the procedure --- by gating
  further tests on the rejection of the root --- ensures that $\Pr(\text{at
  least one false rejection}) \le \alpha$.

  In summary, the law of total probability allows us to break down the overall
  error probability into two parts (depending on whether $p_0 \le \alpha$ or
  not), and since no testing occurs when $p_0 > \alpha$, the entire false
  positive error is controlled by the root’s rejection probability, which is at
  most $\alpha$.

  Thus, the entire procedure controls the FWER at level $\alpha$ under the
  complete null hypothesis.

\end{proof}

\textbf{To Notice:} Although we described the procedure using the idea of data
splitting, this was not necessary in the proof.

\subsection*{Simulation Study}

We created a simple simulation study to illustrate this logic.

Given a specification of a complete $k$-ary tree using $k$ nodes per level and
$l$ levels we drew $p$-values from a uniform distribution following the rules:
For the root node, $p_0 \sim U(0,1)$; a draw which respects the \textbf{false
positive rule} such that $\Pr(p_0 \le \alpha) <= \alpha$ in this case. If $p_0
\le \alpha$, we drew $p_{l=1,k}$ independent $p$-values from $U(p_0,1)$
(implementing the \textbf{monotonicity rule}) otherwise we stopped testing. For
any of the $k$ $p$-values at level 1 where $p_{l=1,k} \le \alpha$, we generated
$p$-values for its children with $U(p_{\text{parent $p$}},1)$, implementing the
\textbf{stopping rule} as we descended into the tree towards the leaves. In
this simulation we did not change the power of the test (i.e. representing the
idea of data splitting) other than to enforce the \textbf{stopping rule} and
\textbf{monotonicity rule}. For each tree, we repeated this procedure 10,000
times, recording whether any of the $p$-values in the tree of true null
hypotheses were $\le \alpha$. The proportion of simulations with at least one
such false rejection is a measure of the FWER.

% see Simple_analysis/results_exploration.R
Table~\ref{tab:weak_control_sim} shows the results. Whether the tree has 2
nodes per level or 100, the rules lead to maximum FWER that are within
simulation error (with 10,000 simulations a rough measure of simulation error
is $2 \times \sqrt{.05 (1-.05)/10000}$ so we would expect results as large as
$.05 +.004 = .054$ given the variability arising from simulation).

\input{weak_control_sim_tab.tex}

Notice that the rules lead the algorithm to nearly always stop after testing
the single root node (which produces $p_0 \le .05$ in less than 5\% of the
simulations). This is true even when the trees have many nodes and many leaves.
In contrast the bottom-up procedure would test in each of the leaves and then
adjust the results of all of those tests. In this table we see that the
bottom-up procedure would be required to do thousands of tests: its FWER would
be controlled (not shown here) and we will show later when the power of the
tests are relevant, this requirement to do so many tests makes the bottom-up
approach very unlikely to detect effects when they exist.

\paragraph*{Why might weak control suffice?}

In many exploratory research scenarios the goal is to identify candidates for
future follow-up studies. Since strong control of the FWER tends to have lower
power than weak control, a researcher may prefer to only apply the three rules
that we describe under the idea that more true effects might be detected in
exchange for a slightly elevated risk of flagging false effects. In the case of
the tree-organized hypotheses, the risk is a function of the number of nodes at
each level of the tree $k$ and the number of levels of the tree $l$ as well as
the proportion of the leaves of the tree with non-null effects or false
hypotheses.

TODO: can we / should we sketch a function that relates them? Such that, say, with very
large $k$ and $l$ we might have a severely uncontrolled FWER but with smaller
trees the trade-off might be worthwhile?


\section{Strong control of the FWER: More Rules}

The three rules that allow control of the FWER in a weak sense do not control
it in a strong sense. For example, Table~\ref{tab:strong_control_naive} shows
the situation where half of the leaves of each tree have non-null causal
effects. All of the ancestors of a leaf with a non-null effect is defined to
also contain a non-null effect (alterantively to be a node for which the null
hypothesis of no effects is false). Whenever the null hypothesis of no effects
is false for any leaf of a tree it is also false for the root of the tree and
for all nodes on the path between the root and that leaf. This table shows that
as the number of nodes per level increase, the minimum FWER also increases
above .05. This table also shows the effects of simulated data splitting: the
rows at the top show less control of the FWER (in all but the smallest trees
the FWER is not controlled) while at the bottom of the table (where "Data
Splitting" is "TRUE"), we see lower false positive rates in the trees with
fewer nodes per level (for example, when $k=2$, the maximum FWER is .05 even
with 18 levels and thus 524,287 total nodes).\footnote{We simulated data
splitting by increasing the parameter of the beta distribution governing the
production of $p$-values for nodes where the null hypothesis of no effects was
false. For example, a Beta distribution with $a=.1$ and $b=1$ will produce
about 74\% of $p$-values less than .05 (in R code we can see this with
\texttt{pbeta(.05,.1,1)}. We represent data splitting as reducing the power of
this test from .74 by dividing by the number of nodes at a given level and then
stopping once the power of the test was roughly .20. In actual practice we
would split the data itself and stop testing once we could no longer split
rather than execute tests on every node in a complete tree as we do in these
simulations.}

\input{strong_control_naive_tab.tex}

%TODO: Show table where it does control and list approaches. They haven in common that they involve an additional adjustment --- whether local (within a level) or global.

However, if we apply one of the additional adjustments to the testing
procedure, we  can control the FWER in a strong sense even with thousands of
potential tests.

%\input{strong_control_tab}

The adjustments:


\paragraph{Local Children Hommel Adjustment} Adjust the $p$-values for all of
the immediate children of a rejected parent. One approach involves two steps.
First, we take all $k$ children of a node that has passed the rejection gate,
"split" the sample, testing the hypothesis of no effects in each of them,
applying the monotonicity rule from above where $\min(p_{l,k})=p_\text{parent}$
for a node $k$ in level $l$, to produce $p^{*}_{l,k}$. Second, we apply the
Hommel adjustment across all $k$ $p$-values to produce $p^{adj}_{l,k}$.
Rejection/gate-passing decisisions for each node are then dependent on
$p^{adj}_{l,k}$. The below table shows strong control of the FWER in a
simulation designed for a situation where half of the leaves in each tree are
non-null, such that the root is always non-null, and using the Beta(.1,1)
distribution to represent the $p$-values that would  be generated by a
relatively powerful test in the presence of a non-null effect.

We notice the average proportion of nodes with false positives is always
bounded from above by .05. We also notice that the gating approach tends to
test many fewer nodes than the bottom up approach. But it tends to identify
nodes with non-null effects. So, its power to detect effects when it tests them
is high. In the extreme case, this approach nearly always rejects non-null
hypotheses in the few leaf nodes that it tests (minimum leaf power is 1), yet
on average the algorithm does not even test a single leaf during each
simulation.

\begin{Verbatim}[fontsize=\footnotesize]
    k min_l max_l max_fwer min_power max_nodes_tested min_leaf_power max_leaves_tested min_bottom_up_power max_leaves bottom_up_detected_leaves
    2     2    18   0.0327     0.738             3.29              1             0.478            0.000437     262144           57.3
    4     2     8   0.0317     0.730             2.91              1             0.451            0.000877      65536           28.7
    6     2     6   0.0346     0.739             2.73              1             0.412            0.00104       46656           24.2
    8     2     6   0.0317     0.732             2.70              1             0.455            0.000437     262144           57.3
   10     2     6   0.0296     0.741             2.64              1             0.454            0.000224    1000000          112.
   12     2     4   0.027      0.748             2.56              1             0.456            0.00156       20736           16.1
   14     2     4   0.0269     0.737             2.49              1             0.467            0.00114       38416           21.9
   16     2     4   0.0251     0.737             2.37              1             0.450            0.000876      65536           28.7
   18     2     4   0.0189     0.731             2.28              1             0.438            0.000693     104976           36.4
   20     2     4   0.0177     0.732             2.14              1             0.389            0.000558     160000           44.7
   50     2     2   0.0175     0.74              2.39              1             0.630            0.00450        2500            5.62
  100     2     2   0.0269     0.739             3.25              1             1.21             0.00225       10000           11.3
\end{Verbatim}

\paragraph{Global Adjustment}

\paragraph{Local rejection threshold adjustment}




%\autocite{miecznikowski2023error}
\subsection{Summary}

We see that not only does the method control FWER for fully ordered hypotheses,
it controls the FWER under a broad range of parallel testing scenarios. This
might be a serious limitation in genomics, where trees might be relatively
shallow (say, no more than 3 levels), but when the trees are created in a data
dependent manner (for example, if the number of tests is 2 at each level and
the tree can be much deeper than 3 levels) this suggests that for all practical
purposes our method controls the FWER.

\clearpage
\printbibliography


\end{document}
